
"""
timm 0.9.10 must be installed to use the get_intermediate_layers method.
    pip install timm==0.9.10
    pip install torch_kmeans

"""
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import os
import requests
import itertools
import timm
import torch
import types
import albumentations as A
from torch.nn import functional as F

from PIL import Image
from sklearn.decomposition import PCA
from torch_kmeans import KMeans, CosineSimilarity
from scene.dinov2 import dinov2_vits14_reg
import cv2

cmap = plt.get_cmap("tab20")
MEAN = np.array([0.3609696,  0.38405442, 0.4348492])
STD = np.array([0.19669543, 0.20297967, 0.22123419])

transforms = A.Compose([
            A.Normalize(mean=list(MEAN), std=list(STD)),
    ])


def get_intermediate_layers(
    self,
    x: torch.Tensor,
    n=1,
    reshape: bool = False,
    return_prefix_tokens: bool = False,
    return_class_token: bool = False,
    norm: bool = True,
):

    outputs = self._intermediate_layers(x, n)
    if norm:
        outputs = [self.norm(out) for out in outputs]
    if return_class_token:
        prefix_tokens = [out[:, 0] for out in outputs]
    else:
        prefix_tokens = [out[:, 0 : self.num_prefix_tokens] for out in outputs]
    outputs = [out[:, self.num_prefix_tokens :] for out in outputs]

    if reshape:
        B, C, H, W = x.shape
        grid_size = (
            (H - self.patch_embed.patch_size[0])
            // self.patch_embed.proj.stride[0]
            + 1,
            (W - self.patch_embed.patch_size[1])
            // self.patch_embed.proj.stride[1]
            + 1,
        )
        outputs = [
            out.reshape(x.shape[0], grid_size[0], grid_size[1], -1)
            .permute(0, 3, 1, 2)
            .contiguous()
            for out in outputs
        ]

    if return_prefix_tokens or return_class_token:
        return tuple(zip(outputs, prefix_tokens))
    return tuple(outputs)


def viz_feat(feat):

    _, _, h, w = feat.shape
    feat = feat.squeeze(0).permute((1,2,0))
    projected_featmap = feat.reshape(-1, feat.shape[-1]).cpu()
    
    pca = PCA(n_components=3)
    pca.fit(projected_featmap)
    pca_features = pca.transform(projected_featmap)
    pca_features = (pca_features - pca_features.min()) / (pca_features.max() - pca_features.min())
    pca_features = pca_features * 255
    res_pred = Image.fromarray(pca_features.reshape(h, w, 3).astype(np.uint8))

    return res_pred


def plot_feats(image, model_option, ori_feats, fine_feats, ori_labels=None, fine_labels=None):

    ori_feats_map = viz_feat(ori_feats)
    fine_feats_map = viz_feat(fine_feats)

    if ori_labels is not None:
        fig, ax = plt.subplots(2, 3, figsize=(10, 5))
        ax[0][0].imshow(image)
        ax[0][0].set_title("Input image", fontsize=15)
        ax[0][1].imshow(ori_feats_map)
        ax[0][1].set_title("Original " + model_option, fontsize=15)
        ax[0][2].imshow(fine_feats_map)
        ax[0][2].set_title("Ours", fontsize=15)
        ax[1][1].imshow(ori_labels)
        ax[1][2].imshow(fine_labels)
        for xx in ax:
          for x in xx:
            x.xaxis.set_major_formatter(plt.NullFormatter())
            x.yaxis.set_major_formatter(plt.NullFormatter())
            x.set_xticks([])
            x.set_yticks([])
            x.axis('off')

    else:
        fig, ax = plt.subplots(1, 3, figsize=(30, 8))
        ax[0].imshow(image)
        ax[0].set_title("Input image", fontsize=15)
        ax[1].imshow(ori_feats_map)
        ax[1].set_title("Original " + model_option, fontsize=15)
        ax[2].imshow(fine_feats_map)
        ax[2].set_title("FiT3D", fontsize=15)

        for x in ax:
          x.xaxis.set_major_formatter(plt.NullFormatter())
          x.yaxis.set_major_formatter(plt.NullFormatter())
          x.set_xticks([])
          x.set_yticks([])
          x.axis('off')

    plt.tight_layout()
    plt.savefig("output3.png")
    # plt.close(fig)
    return fig


def download_image(url, save_path):
    response = requests.get(url)
    with open(save_path, 'wb') as file:
        file.write(response.content)


def process_image(image, stride, transforms):
    transformed = transforms(image=np.array(image))
    image_tensor = torch.tensor(transformed['image'])
    image_tensor = image_tensor.permute(2,0,1)
    image_tensor = image_tensor.unsqueeze(0).to(device)

    h, w = image_tensor.shape[2:]

    height_int = (h // stride)*stride
    width_int = (w // stride)*stride

    image_resized = torch.nn.functional.interpolate(image_tensor, size=(height_int, width_int), mode='bilinear')

    return image_resized


def kmeans_clustering(feats_map, n_clusters=20):

    B, D, h, w = feats_map.shape
    feats_map_flattened = feats_map.permute((0, 2, 3, 1)).reshape(B, -1, D)

    kmeans_engine = KMeans(n_clusters=n_clusters, distance=CosineSimilarity)
    kmeans_engine.fit(feats_map_flattened)
    labels = kmeans_engine.predict(
        feats_map_flattened
        )
    labels = labels.reshape(
        B, h, w
        ).float()
    labels = labels[0].cpu().numpy()

    label_map = cmap(labels / n_clusters)[..., :3]
    label_map = np.uint8(label_map * 255)
    label_map = Image.fromarray(label_map)

    return label_map


def run_demo(original_model, fine_model, image_path, kmeans=20):
    """
    Run the demo for a given model option and image
    model_option: ['DINOv2', 'DINOv2-reg', 'CLIP', 'MAE', 'DeiT-III']
    image_path: path to the image
    kmeans: number of clusters for kmeans. Default is 20. -1 means no kmeans.
    """
    p = original_model.patch_embed.patch_size
    stride = p if isinstance(p, int) else p[0]
    image = Image.open(image_path)
    image_resized = process_image(image, stride, transforms)
    with torch.no_grad():
        ori_feats = original_model.get_intermediate_layers(image_resized, n=[8,9,10,11], reshape=True,
                                    return_class_token=False, norm=True)
        fine_feats = fine_model.get_intermediate_layers(image_resized, n=[8,9,10,11], reshape=True,
                                    return_class_token=False, norm=True)

    ori_feats = ori_feats[-1]
    fine_feats = fine_feats[-1]
    if kmeans != -1:
        ori_labels = kmeans_clustering(ori_feats, kmeans)
        fine_labels = kmeans_clustering(fine_feats, kmeans)
    else:
        ori_labels = None
        fine_labels = None
    print("image shape: ", image.size)
    print("image_resized shape: ", image_resized.shape)
    print("ori_feats shape: ", ori_feats.shape)
    print("fine_feats shape: ", fine_feats.shape)

    return plot_feats(image, "DINOv2-reg", ori_feats, fine_feats, ori_labels, fine_labels), ori_feats, fine_feats


options = ['DINOv2-reg']

timm_model_card = {
    "DINOv2": "vit_small_patch14_dinov2.lvd142m",
    "DINOv2-reg": "vit_small_patch14_reg4_dinov2.lvd142m",
    "CLIP": "vit_base_patch16_clip_384.laion2b_ft_in12k_in1k",
    "MAE": "vit_base_patch16_224.mae",
    "DeiT-III": "deit3_base_patch16_224.fb_in1k"
}

our_model_card = {
    "DINOv2": "dinov2_small_fine",
    "DINOv2-reg": "dinov2_reg_small_fine",
    "CLIP": "clip_base_fine",
    "MAE": "mae_base_fine",
    "DeiT-III": "deit3_base_fine"
}





device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# Pre-load all models
original_models = {}
fine_models = {}

original_model = timm.create_model(
        "vit_small_patch14_reg4_dinov2.lvd142m",
        pretrained=True,
        num_classes=0,
        dynamic_img_size=True,
        dynamic_img_pad=False,
    ).to(device)
original_model.get_intermediate_layers = types.MethodType(
    get_intermediate_layers,
    original_model
)

fine_model = torch.hub.load("ywyue/FiT3D", "dinov2_reg_small_fine").to(device)
fine_model.get_intermediate_layers = types.MethodType(
    get_intermediate_layers,
    fine_model
)


dinov2 = dinov2_vits14_reg(pretrained=True).to(device)
# dinov2.load_state_dict(torch.load("/home/msc-auto/.cache/torch/hub/checkpoints/dinov2_reg_small_finetuned.pth"))

save_feature_map = False

##################################################################################################
# gt_img, rendered_img = "paper_code/gt_image.png", "paper_code/rendered_img.png"
##################################################################################################
if save_feature_map:
    _, ori_feats, fine_feats = run_demo(original_model, fine_model, "paper_code/gt_image.png", kmeans=-1)
    fine_feats_map = viz_feat(fine_feats)
    fine_feats_map =np.array(fine_feats_map)
    fine_feats_map = cv2.cvtColor(fine_feats_map, cv2.COLOR_RGB2BGR)
    print(fine_feats_map.shape)
    cv2.imwrite('paper_code/fit3d_map_gt.png', fine_feats_map)

    ori_feats_map = viz_feat(ori_feats)
    ori_feats_map =np.array(ori_feats_map)
    ori_feats_map = cv2.cvtColor(ori_feats_map, cv2.COLOR_RGB2BGR)
    print(ori_feats_map.shape)
    cv2.imwrite('paper_code/dinov2_map_gt.png', ori_feats_map)

    _, ori_feats, fine_feats = run_demo(original_model, fine_model, "paper_code/rendered_img.png", kmeans=-1)
    fine_feats_map = viz_feat(fine_feats)
    fine_feats_map =np.array(fine_feats_map)
    fine_feats_map = cv2.cvtColor(fine_feats_map, cv2.COLOR_RGB2BGR)
    print(fine_feats_map.shape)
    cv2.imwrite('paper_code/fit3d_map_rendered.png', fine_feats_map)

    ori_feats_map = viz_feat(ori_feats)
    ori_feats_map =np.array(ori_feats_map)
    ori_feats_map = cv2.cvtColor(ori_feats_map, cv2.COLOR_RGB2BGR)
    print(ori_feats_map.shape)
    cv2.imwrite('paper_code/dinov2_map_rendered.png', ori_feats_map)


save_cosine_similarity = True
##################################################################################################
# cosine similarity
##################################################################################################
if save_cosine_similarity:
    _,render_ori_feats,render_fine_feats=run_demo(original_model, fine_model, "paper_code/gt_image.png", kmeans=-1)

    _,gt_ori_feats,gt_fine_feats=run_demo(original_model, fine_model, "paper_code/rendered_img.png", kmeans=-1)
    
    sky_mask = cv2.imread("paper_code/sky_mask.png", cv2.IMREAD_GRAYSCALE) > 0

    # # cosine_ori=F.cosine_similarity(render_ori_feats,gt_ori_feats,dim=1)
    cosine_fine=F.cosine_similarity(render_fine_feats,gt_fine_feats,dim=1)
    # # print(cosine_fine.max(),cosine_fine.min(),cosine_ori.max(),cosine_ori.min())

    # # dino_part_ori=(1 - cosine_ori.sub(0.5).div(0.5)).clip(0.0, 1)
    dino_part_fine=(1 - cosine_fine.sub(0.5).div(0.5)).clip(0.0, 1)

    dino_part_fine = F.interpolate(dino_part_fine.unsqueeze(0), size=(640, 960), mode="bilinear", align_corners=False).squeeze(0)

    # # cosine_ori=cosine_ori.cpu().numpy().squeeze(0)
    # # cosine_fine=cosine_fine.cpu().numpy().squeeze(0)
    # # dino_part_ori=dino_part_ori.cpu().numpy().squeeze(0)
    dino_part_fine=dino_part_fine.cpu().numpy().squeeze(0)

    dino_part_fine[sky_mask] = np.min(dino_part_fine) 
    # dino_part_fine = (dino_part_fine * 255).astype(np.uint8)
    
    cmap = matplotlib.colormaps.get_cmap('Spectral_r')
    # apply colormap
    # dino_part_fine = cv2.applyColorMap(dino_part_fine, cv2.COLORMAP_JET)
    dino_part_fine = cmap(dino_part_fine)[:, :, :3] * 255
    
    # # cv2.imwrite('cosine_ori.png',cosine_ori*255)
    # # cv2.imwrite('cosine_fine.png',cosine_fine*255)
    # # cv2.imwrite('dino_part_ori.png',dino_part_ori*255)
    cv2.imwrite('paper_code/dino_part_fitd_color.png',dino_part_fine)
    # # print(dinov2)